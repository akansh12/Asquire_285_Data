{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import sklearn \n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wheeze_dataframe = pd.read_csv(\"./MFCCs_stasts_Csv/Wheeze_CMN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_set(Asthmatic_Female, Asthmatic_Male, Healthy_Female, Healthy_Male, before_after):\n",
    "    random.seed(0)\n",
    "    test_set = np.concatenate(((np.random.choice(np.array(Asthmatic_Male), replace=False, size=(4)),\n",
    "                                np.random.choice(np.array(Asthmatic_Female), replace=False, size=(4)),\n",
    "                                np.random.choice(np.array(Healthy_Male), replace=False, size=(4)),\n",
    "                                np.random.choice(np.array(Healthy_Female), replace=False, size=(4)))))\n",
    "    train_set = np.concatenate((np.array(Asthmatic_Male),\n",
    "                                np.array(Asthmatic_Female),\n",
    "                                np.array(Healthy_Male),\n",
    "                                np.array(Healthy_Female)))\n",
    "    train_set = np.setdiff1d(train_set,test_set)\n",
    "#     np.array(before_after).shape\n",
    "    train_set = np.concatenate((train_set, np.array(before_after)))\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test Csv\n",
    "def train_test_csv(sound_dataframe):\n",
    "    Total = np.unique(sound_dataframe.iloc[:,sound_dataframe.shape[1]-1])\n",
    "    name = []\n",
    "    for i in Total:\n",
    "        name.append(i[:4])\n",
    "\n",
    "    unique = []\n",
    "    before_after = []\n",
    "    for i in Total:\n",
    "        if np.sum((np.array(name, dtype = int) == int(i[:4]))) == 1:\n",
    "            unique.append(i)\n",
    "        else:\n",
    "            before_after.append(i) \n",
    "\n",
    "    Asthmatic_Female = []\n",
    "    Asthmatic_Male = []\n",
    "    Healthy_Male = []\n",
    "    Healthy_Female = []\n",
    "    for file in unique:\n",
    "        if file.find('sthma') !=-1:\n",
    "            if file.find(\"_M_\")!=-1:\n",
    "                Asthmatic_Male.append(file)\n",
    "            if file.find(\"_F_\")!=-1:\n",
    "                Asthmatic_Female.append(file)\n",
    "        if file.find(\"_C_\")!=-1:\n",
    "            if file.find(\"_M_\")!=-1:\n",
    "                Healthy_Male.append(file)\n",
    "            if file.find(\"_F_\")!=-1:\n",
    "                Healthy_Female.append(file)\n",
    "\n",
    "                \n",
    "\n",
    "    Train, Test = train_test_set(Asthmatic_Female, Asthmatic_Male, Healthy_Female, Healthy_Male, before_after)     \n",
    "\n",
    "    test_dataframe = pd.DataFrame()\n",
    "    for i, line in enumerate(Test):\n",
    "        A = sound_dataframe[(sound_dataframe[str(sound_dataframe.shape[1]-1)] == (Test[i]))]\n",
    "        test_dataframe = pd.DataFrame.append(test_dataframe,A)\n",
    "        \n",
    "        \n",
    "    train_dataframe = pd.DataFrame()\n",
    "    for i, line in enumerate(Train):\n",
    "        A = sound_dataframe[(sound_dataframe[str(sound_dataframe.shape[1]-1)] == (Train[i]))]\n",
    "        train_dataframe = pd.DataFrame.append(train_dataframe,A) \n",
    "        \n",
    "        \n",
    "    \n",
    "    return train_dataframe, test_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning Algorithm (MLA) Selection and Initialization\n",
    "def MLA_selection(sound_dataframe, sound):    \n",
    "    MLA = [\n",
    "        #Ensemble Methods\n",
    "        ensemble.AdaBoostClassifier(),\n",
    "        ensemble.BaggingClassifier(),\n",
    "        ensemble.ExtraTreesClassifier(),\n",
    "        ensemble.GradientBoostingClassifier(),\n",
    "        ensemble.RandomForestClassifier(),\n",
    "\n",
    "        #Gaussian Processes\n",
    "        gaussian_process.GaussianProcessClassifier(),\n",
    "\n",
    "        #GLM\n",
    "        linear_model.LogisticRegressionCV(),\n",
    "        linear_model.PassiveAggressiveClassifier(),\n",
    "        linear_model.RidgeClassifierCV(),\n",
    "        linear_model.SGDClassifier(),\n",
    "        linear_model.Perceptron(),\n",
    "\n",
    "        #Navies Bayes\n",
    "        naive_bayes.BernoulliNB(),\n",
    "        naive_bayes.GaussianNB(),\n",
    "\n",
    "        #Nearest Neighbor\n",
    "        neighbors.KNeighborsClassifier(),\n",
    "\n",
    "        #SVM\n",
    "        svm.SVC(probability=True),\n",
    "        svm.NuSVC(probability=True),\n",
    "        svm.LinearSVC(),\n",
    "\n",
    "        #Trees    \n",
    "        tree.DecisionTreeClassifier(),\n",
    "        tree.ExtraTreeClassifier(),\n",
    "\n",
    "        #Discriminant Analysis\n",
    "        discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "        discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "\n",
    "        XGBClassifier(max_depth = 8,\n",
    "                     subsample = 0.8,\n",
    "                     learning_rate = 0.01,\n",
    "                     n_estimators = 450,\n",
    "                     min_child_weight = 1)\n",
    "#         XGBClassifier()\n",
    "        ]\n",
    "\n",
    "\n",
    "    MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy','MLA Train Accuracy Mean', 'MLA Test Accuracy', 'MLA Test Accuracy Mean','MLA Test Accuracy Std' ]\n",
    "    MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "    row_index = 0\n",
    "    for alg in MLA:\n",
    "        MLA_name = alg.__class__.__name__\n",
    "        MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "        MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "        test = []\n",
    "        train = []\n",
    "        for i in range(0,10):\n",
    "            train_csv, test_csv = pd.read_csv('./Set_CSV/train'+sound+str(i)+'.csv'), pd.read_csv('./Set_CSV/test'+sound+str(i)+'.csv')\n",
    "            X_train = train_csv.iloc[:,:sound_dataframe.shape[1]-2]\n",
    "            y_train = train_csv.iloc[:,sound_dataframe.shape[1]-2]\n",
    "            X_test = test_csv.iloc[:,:sound_dataframe.shape[1]-2]\n",
    "            y_test = test_csv.iloc[:,sound_dataframe.shape[1]-2]\n",
    "            #Scaling\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            X_train = pd.DataFrame(X_train)\n",
    "            X_test = pd.DataFrame(X_test)\n",
    "\n",
    "            alg.fit(X_train,y_train)\n",
    "            test.append(metrics.accuracy_score(y_test,alg.predict(X_test)))\n",
    "\n",
    "            train.append(metrics.accuracy_score(y_train,alg.predict(X_train)))\n",
    "            \n",
    "#             if alg.__class__.__name__ == 'XGBClassifier':\n",
    "#                 filename = './CMN/XGB_model'+ str(i) + '.model'\n",
    "#                 pickle.dump(alg, open(filename, 'wb'))\n",
    "#                 train_csv.to_csv('./CMN/Train_XGB'+str(i)+'.csv', index=False)\n",
    "                \n",
    "        \n",
    "        MLA_compare.loc[row_index, 'MLA Train Accuracy'] = train\n",
    "        MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = np.mean(train)\n",
    "        MLA_compare.loc[row_index, 'MLA Test Accuracy'] = test\n",
    "        MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = np.mean(test)\n",
    "        MLA_compare.loc[row_index, 'MLA Test Accuracy Std'] = np.std(test)\n",
    "\n",
    "\n",
    "        row_index+=1\n",
    "\n",
    "    \n",
    "    MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
    "    \n",
    "    return MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:41:36] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:39] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:42] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:46] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:52] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:55] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:58] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:42:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:42:04] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "MLA_Wheeze = MLA_selection(Wheeze_dataframe, 'Wheeze_CMN') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train Accuracy</th>\n",
       "      <th>MLA Train Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy</th>\n",
       "      <th>MLA Test Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.8931623931623932, 0.7619047619047619, 0.922...</td>\n",
       "      <td>0.870088</td>\n",
       "      <td>0.0492989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>[0.9992748368382887, 1.0, 0.9992684711046086, ...</td>\n",
       "      <td>0.999414</td>\n",
       "      <td>[0.9017094017094017, 0.753968253968254, 0.9024...</td>\n",
       "      <td>0.868901</td>\n",
       "      <td>0.054507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>[0.9949238578680203, 0.9955914768552535, 0.992...</td>\n",
       "      <td>0.993416</td>\n",
       "      <td>[0.8675213675213675, 0.7222222222222222, 0.898...</td>\n",
       "      <td>0.861209</td>\n",
       "      <td>0.0567945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>[0.9361856417693981, 0.9537105069801617, 0.934...</td>\n",
       "      <td>0.945755</td>\n",
       "      <td>[0.8333333333333334, 0.7341269841269841, 0.861...</td>\n",
       "      <td>0.833952</td>\n",
       "      <td>0.0456194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.8076923076923077, 0.753968253968254, 0.9024...</td>\n",
       "      <td>0.833407</td>\n",
       "      <td>0.0498345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>[0.9963741841914431, 0.9977957384276267, 0.994...</td>\n",
       "      <td>0.996201</td>\n",
       "      <td>[0.8931623931623932, 0.6984126984126984, 0.882...</td>\n",
       "      <td>0.831952</td>\n",
       "      <td>0.0653338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n",
       "      <td>[0.896301667875272, 0.9191770756796473, 0.8961...</td>\n",
       "      <td>0.90144</td>\n",
       "      <td>[0.8205128205128205, 0.7301587301587301, 0.837...</td>\n",
       "      <td>0.824632</td>\n",
       "      <td>0.042931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>{'Cs': 10, 'class_weight': None, 'cv': None, '...</td>\n",
       "      <td>[0.8912255257432923, 0.9155033063923586, 0.892...</td>\n",
       "      <td>0.891077</td>\n",
       "      <td>[0.811965811965812, 0.7341269841269841, 0.8577...</td>\n",
       "      <td>0.823709</td>\n",
       "      <td>0.043721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>{'covariance_estimator': None, 'n_components':...</td>\n",
       "      <td>[0.8868745467730239, 0.9162380602498164, 0.887...</td>\n",
       "      <td>0.893972</td>\n",
       "      <td>[0.7863247863247863, 0.7579365079365079, 0.833...</td>\n",
       "      <td>0.818333</td>\n",
       "      <td>0.0497408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>{'alphas': array([ 0.1,  1. , 10. ]), 'class_w...</td>\n",
       "      <td>[0.8875997099347354, 0.9162380602498164, 0.888...</td>\n",
       "      <td>0.893971</td>\n",
       "      <td>[0.7777777777777778, 0.75, 0.8373983739837398,...</td>\n",
       "      <td>0.818133</td>\n",
       "      <td>0.0485332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.8675213675213675, 0.7261904761904762, 0.873...</td>\n",
       "      <td>0.814076</td>\n",
       "      <td>0.0509836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n",
       "      <td>[0.9746192893401016, 0.9772226304188097, 0.967...</td>\n",
       "      <td>0.973311</td>\n",
       "      <td>[0.8034188034188035, 0.6746031746031746, 0.869...</td>\n",
       "      <td>0.811649</td>\n",
       "      <td>0.0604255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NuSVC</td>\n",
       "      <td>{'break_ties': False, 'cache_size': 200, 'clas...</td>\n",
       "      <td>[0.9274836838288615, 0.9309331373989713, 0.932...</td>\n",
       "      <td>0.935489</td>\n",
       "      <td>[0.7991452991452992, 0.6626984126984127, 0.837...</td>\n",
       "      <td>0.806171</td>\n",
       "      <td>0.0607707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n",
       "      <td>[0.8527918781725888, 0.899338721528288, 0.8632...</td>\n",
       "      <td>0.862533</td>\n",
       "      <td>[0.7521367521367521, 0.7341269841269841, 0.780...</td>\n",
       "      <td>0.803868</td>\n",
       "      <td>0.0383864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n",
       "      <td>[0.807831762146483, 0.8295371050698016, 0.8061...</td>\n",
       "      <td>0.813025</td>\n",
       "      <td>[0.7350427350427351, 0.7341269841269841, 0.813...</td>\n",
       "      <td>0.787384</td>\n",
       "      <td>0.0521572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n",
       "      <td>[0.8281363306744017, 0.896399706098457, 0.8273...</td>\n",
       "      <td>0.849599</td>\n",
       "      <td>[0.7777777777777778, 0.7063492063492064, 0.752...</td>\n",
       "      <td>0.776253</td>\n",
       "      <td>0.0491688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>{'C': 1.0, 'average': False, 'class_weight': N...</td>\n",
       "      <td>[0.851341551849166, 0.8758265980896399, 0.8529...</td>\n",
       "      <td>0.831463</td>\n",
       "      <td>[0.7478632478632479, 0.6746031746031746, 0.873...</td>\n",
       "      <td>0.771662</td>\n",
       "      <td>0.0605767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>[0.9869470630891951, 0.9860396767083027, 0.986...</td>\n",
       "      <td>0.985012</td>\n",
       "      <td>[0.7564102564102564, 0.6746031746031746, 0.825...</td>\n",
       "      <td>0.768181</td>\n",
       "      <td>0.0502495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>\n",
       "      <td>[0.9448875997099347, 0.9544452608376194, 0.940...</td>\n",
       "      <td>0.949923</td>\n",
       "      <td>[0.8076923076923077, 0.6666666666666666, 0.735...</td>\n",
       "      <td>0.765952</td>\n",
       "      <td>0.0527985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>[0.8194343727338651, 0.8295371050698016, 0.803...</td>\n",
       "      <td>0.81023</td>\n",
       "      <td>[0.717948717948718, 0.7182539682539683, 0.7723...</td>\n",
       "      <td>0.758647</td>\n",
       "      <td>0.0526969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6709401709401709, 0.6746031746031746, 0.796...</td>\n",
       "      <td>0.734378</td>\n",
       "      <td>0.0548601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.7008547008547008, 0.6865079365079365, 0.691...</td>\n",
       "      <td>0.68281</td>\n",
       "      <td>0.0260504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "4          RandomForestClassifier   \n",
       "21                  XGBClassifier   \n",
       "3      GradientBoostingClassifier   \n",
       "0              AdaBoostClassifier   \n",
       "2            ExtraTreesClassifier   \n",
       "1               BaggingClassifier   \n",
       "16                      LinearSVC   \n",
       "6            LogisticRegressionCV   \n",
       "19     LinearDiscriminantAnalysis   \n",
       "8               RidgeClassifierCV   \n",
       "17         DecisionTreeClassifier   \n",
       "14                            SVC   \n",
       "15                          NuSVC   \n",
       "9                   SGDClassifier   \n",
       "11                    BernoulliNB   \n",
       "10                     Perceptron   \n",
       "7     PassiveAggressiveClassifier   \n",
       "13           KNeighborsClassifier   \n",
       "20  QuadraticDiscriminantAnalysis   \n",
       "12                     GaussianNB   \n",
       "5       GaussianProcessClassifier   \n",
       "18            ExtraTreeClassifier   \n",
       "\n",
       "                                       MLA Parameters  \\\n",
       "4   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...   \n",
       "21  {'objective': 'binary:logistic', 'use_label_en...   \n",
       "3   {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...   \n",
       "0   {'algorithm': 'SAMME.R', 'base_estimator': Non...   \n",
       "2   {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...   \n",
       "1   {'base_estimator': None, 'bootstrap': True, 'b...   \n",
       "16  {'C': 1.0, 'class_weight': None, 'dual': True,...   \n",
       "6   {'Cs': 10, 'class_weight': None, 'cv': None, '...   \n",
       "19  {'covariance_estimator': None, 'n_components':...   \n",
       "8   {'alphas': array([ 0.1,  1. , 10. ]), 'class_w...   \n",
       "17  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...   \n",
       "14  {'C': 1.0, 'break_ties': False, 'cache_size': ...   \n",
       "15  {'break_ties': False, 'cache_size': 200, 'clas...   \n",
       "9   {'alpha': 0.0001, 'average': False, 'class_wei...   \n",
       "11  {'alpha': 1.0, 'binarize': 0.0, 'class_prior':...   \n",
       "10  {'alpha': 0.0001, 'class_weight': None, 'early...   \n",
       "7   {'C': 1.0, 'average': False, 'class_weight': N...   \n",
       "13  {'algorithm': 'auto', 'leaf_size': 30, 'metric...   \n",
       "20  {'priors': None, 'reg_param': 0.0, 'store_cova...   \n",
       "12           {'priors': None, 'var_smoothing': 1e-09}   \n",
       "5   {'copy_X_train': True, 'kernel': None, 'max_it...   \n",
       "18  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...   \n",
       "\n",
       "                                   MLA Train Accuracy MLA Train Accuracy Mean  \\\n",
       "4   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "21  [0.9992748368382887, 1.0, 0.9992684711046086, ...                0.999414   \n",
       "3   [0.9949238578680203, 0.9955914768552535, 0.992...                0.993416   \n",
       "0   [0.9361856417693981, 0.9537105069801617, 0.934...                0.945755   \n",
       "2   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "1   [0.9963741841914431, 0.9977957384276267, 0.994...                0.996201   \n",
       "16  [0.896301667875272, 0.9191770756796473, 0.8961...                 0.90144   \n",
       "6   [0.8912255257432923, 0.9155033063923586, 0.892...                0.891077   \n",
       "19  [0.8868745467730239, 0.9162380602498164, 0.887...                0.893972   \n",
       "8   [0.8875997099347354, 0.9162380602498164, 0.888...                0.893971   \n",
       "17  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "14  [0.9746192893401016, 0.9772226304188097, 0.967...                0.973311   \n",
       "15  [0.9274836838288615, 0.9309331373989713, 0.932...                0.935489   \n",
       "9   [0.8527918781725888, 0.899338721528288, 0.8632...                0.862533   \n",
       "11  [0.807831762146483, 0.8295371050698016, 0.8061...                0.813025   \n",
       "10  [0.8281363306744017, 0.896399706098457, 0.8273...                0.849599   \n",
       "7   [0.851341551849166, 0.8758265980896399, 0.8529...                0.831463   \n",
       "13  [0.9869470630891951, 0.9860396767083027, 0.986...                0.985012   \n",
       "20  [0.9448875997099347, 0.9544452608376194, 0.940...                0.949923   \n",
       "12  [0.8194343727338651, 0.8295371050698016, 0.803...                 0.81023   \n",
       "5   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "18  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "\n",
       "                                    MLA Test Accuracy MLA Test Accuracy Mean  \\\n",
       "4   [0.8931623931623932, 0.7619047619047619, 0.922...               0.870088   \n",
       "21  [0.9017094017094017, 0.753968253968254, 0.9024...               0.868901   \n",
       "3   [0.8675213675213675, 0.7222222222222222, 0.898...               0.861209   \n",
       "0   [0.8333333333333334, 0.7341269841269841, 0.861...               0.833952   \n",
       "2   [0.8076923076923077, 0.753968253968254, 0.9024...               0.833407   \n",
       "1   [0.8931623931623932, 0.6984126984126984, 0.882...               0.831952   \n",
       "16  [0.8205128205128205, 0.7301587301587301, 0.837...               0.824632   \n",
       "6   [0.811965811965812, 0.7341269841269841, 0.8577...               0.823709   \n",
       "19  [0.7863247863247863, 0.7579365079365079, 0.833...               0.818333   \n",
       "8   [0.7777777777777778, 0.75, 0.8373983739837398,...               0.818133   \n",
       "17  [0.8675213675213675, 0.7261904761904762, 0.873...               0.814076   \n",
       "14  [0.8034188034188035, 0.6746031746031746, 0.869...               0.811649   \n",
       "15  [0.7991452991452992, 0.6626984126984127, 0.837...               0.806171   \n",
       "9   [0.7521367521367521, 0.7341269841269841, 0.780...               0.803868   \n",
       "11  [0.7350427350427351, 0.7341269841269841, 0.813...               0.787384   \n",
       "10  [0.7777777777777778, 0.7063492063492064, 0.752...               0.776253   \n",
       "7   [0.7478632478632479, 0.6746031746031746, 0.873...               0.771662   \n",
       "13  [0.7564102564102564, 0.6746031746031746, 0.825...               0.768181   \n",
       "20  [0.8076923076923077, 0.6666666666666666, 0.735...               0.765952   \n",
       "12  [0.717948717948718, 0.7182539682539683, 0.7723...               0.758647   \n",
       "5   [0.6709401709401709, 0.6746031746031746, 0.796...               0.734378   \n",
       "18  [0.7008547008547008, 0.6865079365079365, 0.691...                0.68281   \n",
       "\n",
       "   MLA Test Accuracy Std  \n",
       "4              0.0492989  \n",
       "21              0.054507  \n",
       "3              0.0567945  \n",
       "0              0.0456194  \n",
       "2              0.0498345  \n",
       "1              0.0653338  \n",
       "16              0.042931  \n",
       "6               0.043721  \n",
       "19             0.0497408  \n",
       "8              0.0485332  \n",
       "17             0.0509836  \n",
       "14             0.0604255  \n",
       "15             0.0607707  \n",
       "9              0.0383864  \n",
       "11             0.0521572  \n",
       "10             0.0491688  \n",
       "7              0.0605767  \n",
       "13             0.0502495  \n",
       "20             0.0527985  \n",
       "12             0.0526969  \n",
       "5              0.0548601  \n",
       "18             0.0260504  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLA_Wheeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_dataframe = Wheeze_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total = np.unique(sound_dataframe.iloc[:,sound_dataframe.shape[1]-1])\n",
    "name = []\n",
    "for i in Total:\n",
    "    name.append(i[:4])\n",
    "\n",
    "unique = []\n",
    "before_after = []\n",
    "for i in Total:\n",
    "    if np.sum((np.array(name, dtype = int) == int(i[:4]))) == 1:\n",
    "        unique.append(i)\n",
    "    else:\n",
    "        before_after.append(i) \n",
    "\n",
    "Asthmatic_Female = []\n",
    "Asthmatic_Male = []\n",
    "Healthy_Male = []\n",
    "Healthy_Female = []\n",
    "for file in unique:\n",
    "    if file.find('sthma') !=-1:\n",
    "        if file.find(\"_M_\")!=-1:\n",
    "            Asthmatic_Male.append(file)\n",
    "        if file.find(\"_F_\")!=-1:\n",
    "            Asthmatic_Female.append(file)\n",
    "    if file.find(\"_C_\")!=-1:\n",
    "        if file.find(\"_M_\")!=-1:\n",
    "            Healthy_Male.append(file)\n",
    "        if file.find(\"_F_\")!=-1:\n",
    "            Healthy_Female.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_wheeze_dataframe = pd.DataFrame()\n",
    "after_wheeze_dataframe = pd.DataFrame()\n",
    "for i in (np.unique(Wheeze_dataframe['73'])):\n",
    "    if i.find('_before_') != -1 or i.find('_C_') !=-1:\n",
    "        A = Wheeze_dataframe[Wheeze_dataframe['73'] == i]\n",
    "        before_wheeze_dataframe = pd.DataFrame.append(before_wheeze_dataframe,A)\n",
    "    if i.find('_after_') != -1 or i.find('_C_') !=-1:\n",
    "        B = Wheeze_dataframe[Wheeze_dataframe['73'] == i]\n",
    "        after_wheeze_dataframe = pd.DataFrame.append(after_wheeze_dataframe,B)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133,)\n",
      "(131,)\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(before_wheeze_dataframe['73']).shape)\n",
    "print(np.unique(after_wheeze_dataframe['73']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_and_save_sets(sound_dataframe, sound):\n",
    "    for i in range(0,10):\n",
    "        train_csv, test_csv = train_test_csv(sound_dataframe)\n",
    "        train_csv.to_csv('./Set_CSV/train'+sound+str(i)+'.csv', index=False)\n",
    "        test_csv.to_csv('./Set_CSV/test'+sound+str(i)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_and_save_sets(before_wheeze_dataframe, 'before_wheeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_and_save_sets(after_wheeze_dataframe, 'after_wheeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:35:57] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:35:58] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:35:58] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:35:59] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:36:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:36:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:36:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:36:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:36:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:36:04] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "MLA_Wheeze_before = MLA_selection(before_wheeze_dataframe, 'before_wheeze') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train Accuracy</th>\n",
       "      <th>MLA Train Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy</th>\n",
       "      <th>MLA Test Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.8135593220338984, 0.7107438016528925, 0.861...</td>\n",
       "      <td>0.808997</td>\n",
       "      <td>0.0832143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.8135593220338984, 0.8760330578512396, 0.788...</td>\n",
       "      <td>0.798247</td>\n",
       "      <td>0.0986386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NuSVC</td>\n",
       "      <td>{'break_ties': False, 'cache_size': 200, 'clas...</td>\n",
       "      <td>[0.9859578736208626, 0.9678068410462777, 0.975...</td>\n",
       "      <td>0.975089</td>\n",
       "      <td>[0.8135593220338984, 0.8264462809917356, 0.854...</td>\n",
       "      <td>0.797912</td>\n",
       "      <td>0.077087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.8135593220338984, 0.768595041322314, 0.8613...</td>\n",
       "      <td>0.7917</td>\n",
       "      <td>0.105391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>{'Cs': 10, 'class_weight': None, 'cv': None, '...</td>\n",
       "      <td>[0.8916750250752257, 0.9104627766599598, 0.941...</td>\n",
       "      <td>0.913744</td>\n",
       "      <td>[0.6949152542372882, 0.7933884297520661, 0.788...</td>\n",
       "      <td>0.780798</td>\n",
       "      <td>0.0752533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6779661016949152, 0.7933884297520661, 0.861...</td>\n",
       "      <td>0.755687</td>\n",
       "      <td>0.0582586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>[0.8665997993981945, 0.8470824949698189, 0.850...</td>\n",
       "      <td>0.858446</td>\n",
       "      <td>[0.7203389830508474, 0.8264462809917356, 0.744...</td>\n",
       "      <td>0.750785</td>\n",
       "      <td>0.0757055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n",
       "      <td>[0.8796389167502507, 0.8651911468812877, 0.847...</td>\n",
       "      <td>0.857235</td>\n",
       "      <td>[0.7457627118644068, 0.628099173553719, 0.8175...</td>\n",
       "      <td>0.746141</td>\n",
       "      <td>0.0915189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.8813559322033898, 0.7933884297520661, 0.788...</td>\n",
       "      <td>0.745598</td>\n",
       "      <td>0.10998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9959595959595...</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>[0.7033898305084746, 0.8512396694214877, 0.744...</td>\n",
       "      <td>0.731016</td>\n",
       "      <td>0.100849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6186440677966102, 0.7933884297520661, 0.751...</td>\n",
       "      <td>0.726592</td>\n",
       "      <td>0.0613639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>{'alphas': array([ 0.1,  1. , 10. ]), 'class_w...</td>\n",
       "      <td>[0.9949849548645938, 0.9798792756539235, 0.962...</td>\n",
       "      <td>0.969553</td>\n",
       "      <td>[0.6440677966101694, 0.628099173553719, 0.8905...</td>\n",
       "      <td>0.724574</td>\n",
       "      <td>0.0975513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9929292929292...</td>\n",
       "      <td>0.997776</td>\n",
       "      <td>[0.6186440677966102, 0.8512396694214877, 0.788...</td>\n",
       "      <td>0.720889</td>\n",
       "      <td>0.114854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>{'covariance_estimator': None, 'n_components':...</td>\n",
       "      <td>[1.0, 0.971830985915493, 0.967280163599182, 0....</td>\n",
       "      <td>0.970793</td>\n",
       "      <td>[0.5677966101694916, 0.628099173553719, 0.8905...</td>\n",
       "      <td>0.708043</td>\n",
       "      <td>0.102956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6186440677966102, 0.768595041322314, 0.8175...</td>\n",
       "      <td>0.705148</td>\n",
       "      <td>0.126191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>{'C': 1.0, 'average': False, 'class_weight': N...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6186440677966102, 0.768595041322314, 0.8175...</td>\n",
       "      <td>0.702483</td>\n",
       "      <td>0.116041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6779661016949152, 0.628099173553719, 0.7518...</td>\n",
       "      <td>0.698987</td>\n",
       "      <td>0.0728596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6016949152542372, 0.38016528925619836, 0.75...</td>\n",
       "      <td>0.668284</td>\n",
       "      <td>0.110717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>[1.0, 0.9989939637826962, 0.9989775051124744, ...</td>\n",
       "      <td>0.99929</td>\n",
       "      <td>[0.5932203389830508, 0.5537190082644629, 0.861...</td>\n",
       "      <td>0.664306</td>\n",
       "      <td>0.122134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.5932203389830508, 0.47107438016528924, 0.86...</td>\n",
       "      <td>0.655388</td>\n",
       "      <td>0.127855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6016949152542372, 0.6198347107438017, 0.554...</td>\n",
       "      <td>0.616078</td>\n",
       "      <td>0.128972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6016949152542372, 0.48760330578512395, 0.46...</td>\n",
       "      <td>0.510102</td>\n",
       "      <td>0.0493417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "4          RandomForestClassifier   \n",
       "2            ExtraTreesClassifier   \n",
       "15                          NuSVC   \n",
       "14                            SVC   \n",
       "6            LogisticRegressionCV   \n",
       "3      GradientBoostingClassifier   \n",
       "12                     GaussianNB   \n",
       "11                    BernoulliNB   \n",
       "0              AdaBoostClassifier   \n",
       "10                     Perceptron   \n",
       "21                  XGBClassifier   \n",
       "8               RidgeClassifierCV   \n",
       "9                   SGDClassifier   \n",
       "19     LinearDiscriminantAnalysis   \n",
       "16                      LinearSVC   \n",
       "7     PassiveAggressiveClassifier   \n",
       "1               BaggingClassifier   \n",
       "17         DecisionTreeClassifier   \n",
       "13           KNeighborsClassifier   \n",
       "5       GaussianProcessClassifier   \n",
       "18            ExtraTreeClassifier   \n",
       "20  QuadraticDiscriminantAnalysis   \n",
       "\n",
       "                                       MLA Parameters  \\\n",
       "4   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...   \n",
       "2   {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...   \n",
       "15  {'break_ties': False, 'cache_size': 200, 'clas...   \n",
       "14  {'C': 1.0, 'break_ties': False, 'cache_size': ...   \n",
       "6   {'Cs': 10, 'class_weight': None, 'cv': None, '...   \n",
       "3   {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...   \n",
       "12           {'priors': None, 'var_smoothing': 1e-09}   \n",
       "11  {'alpha': 1.0, 'binarize': 0.0, 'class_prior':...   \n",
       "0   {'algorithm': 'SAMME.R', 'base_estimator': Non...   \n",
       "10  {'alpha': 0.0001, 'class_weight': None, 'early...   \n",
       "21  {'objective': 'binary:logistic', 'use_label_en...   \n",
       "8   {'alphas': array([ 0.1,  1. , 10. ]), 'class_w...   \n",
       "9   {'alpha': 0.0001, 'average': False, 'class_wei...   \n",
       "19  {'covariance_estimator': None, 'n_components':...   \n",
       "16  {'C': 1.0, 'class_weight': None, 'dual': True,...   \n",
       "7   {'C': 1.0, 'average': False, 'class_weight': N...   \n",
       "1   {'base_estimator': None, 'bootstrap': True, 'b...   \n",
       "17  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...   \n",
       "13  {'algorithm': 'auto', 'leaf_size': 30, 'metric...   \n",
       "5   {'copy_X_train': True, 'kernel': None, 'max_it...   \n",
       "18  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...   \n",
       "20  {'priors': None, 'reg_param': 0.0, 'store_cova...   \n",
       "\n",
       "                                   MLA Train Accuracy MLA Train Accuracy Mean  \\\n",
       "4   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "2   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "15  [0.9859578736208626, 0.9678068410462777, 0.975...                0.975089   \n",
       "14  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "6   [0.8916750250752257, 0.9104627766599598, 0.941...                0.913744   \n",
       "3   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "12  [0.8665997993981945, 0.8470824949698189, 0.850...                0.858446   \n",
       "11  [0.8796389167502507, 0.8651911468812877, 0.847...                0.857235   \n",
       "0   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "10  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9959595959595...                0.999596   \n",
       "21  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "8   [0.9949849548645938, 0.9798792756539235, 0.962...                0.969553   \n",
       "9   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9929292929292...                0.997776   \n",
       "19  [1.0, 0.971830985915493, 0.967280163599182, 0....                0.970793   \n",
       "16  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "7   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "1   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "17  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "13  [1.0, 0.9989939637826962, 0.9989775051124744, ...                 0.99929   \n",
       "5   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "18  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "20  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "\n",
       "                                    MLA Test Accuracy MLA Test Accuracy Mean  \\\n",
       "4   [0.8135593220338984, 0.7107438016528925, 0.861...               0.808997   \n",
       "2   [0.8135593220338984, 0.8760330578512396, 0.788...               0.798247   \n",
       "15  [0.8135593220338984, 0.8264462809917356, 0.854...               0.797912   \n",
       "14  [0.8135593220338984, 0.768595041322314, 0.8613...                 0.7917   \n",
       "6   [0.6949152542372882, 0.7933884297520661, 0.788...               0.780798   \n",
       "3   [0.6779661016949152, 0.7933884297520661, 0.861...               0.755687   \n",
       "12  [0.7203389830508474, 0.8264462809917356, 0.744...               0.750785   \n",
       "11  [0.7457627118644068, 0.628099173553719, 0.8175...               0.746141   \n",
       "0   [0.8813559322033898, 0.7933884297520661, 0.788...               0.745598   \n",
       "10  [0.7033898305084746, 0.8512396694214877, 0.744...               0.731016   \n",
       "21  [0.6186440677966102, 0.7933884297520661, 0.751...               0.726592   \n",
       "8   [0.6440677966101694, 0.628099173553719, 0.8905...               0.724574   \n",
       "9   [0.6186440677966102, 0.8512396694214877, 0.788...               0.720889   \n",
       "19  [0.5677966101694916, 0.628099173553719, 0.8905...               0.708043   \n",
       "16  [0.6186440677966102, 0.768595041322314, 0.8175...               0.705148   \n",
       "7   [0.6186440677966102, 0.768595041322314, 0.8175...               0.702483   \n",
       "1   [0.6779661016949152, 0.628099173553719, 0.7518...               0.698987   \n",
       "17  [0.6016949152542372, 0.38016528925619836, 0.75...               0.668284   \n",
       "13  [0.5932203389830508, 0.5537190082644629, 0.861...               0.664306   \n",
       "5   [0.5932203389830508, 0.47107438016528924, 0.86...               0.655388   \n",
       "18  [0.6016949152542372, 0.6198347107438017, 0.554...               0.616078   \n",
       "20  [0.6016949152542372, 0.48760330578512395, 0.46...               0.510102   \n",
       "\n",
       "   MLA Test Accuracy Std  \n",
       "4              0.0832143  \n",
       "2              0.0986386  \n",
       "15              0.077087  \n",
       "14              0.105391  \n",
       "6              0.0752533  \n",
       "3              0.0582586  \n",
       "12             0.0757055  \n",
       "11             0.0915189  \n",
       "0                0.10998  \n",
       "10              0.100849  \n",
       "21             0.0613639  \n",
       "8              0.0975513  \n",
       "9               0.114854  \n",
       "19              0.102956  \n",
       "16              0.126191  \n",
       "7               0.116041  \n",
       "1              0.0728596  \n",
       "17              0.110717  \n",
       "13              0.122134  \n",
       "5               0.127855  \n",
       "18              0.128972  \n",
       "20             0.0493417  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLA_Wheeze_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:37:07] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:37:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:37:09] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:37:10] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:37:11] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:37:11] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:37:12] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:37:13] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:37:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:37:15] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "MLA_Wheeze_after = MLA_selection(after_wheeze_dataframe, 'after_wheeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train Accuracy</th>\n",
       "      <th>MLA Train Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy</th>\n",
       "      <th>MLA Test Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.8222222222222222, 0.7612903225806451, 0.946...</td>\n",
       "      <td>0.805953</td>\n",
       "      <td>0.0750491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6148148148148148, 0.9354838709677419, 0.806...</td>\n",
       "      <td>0.795489</td>\n",
       "      <td>0.0865326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NuSVC</td>\n",
       "      <td>{'break_ties': False, 'cache_size': 200, 'clas...</td>\n",
       "      <td>[0.9698492462311558, 0.9774358974358974, 0.974...</td>\n",
       "      <td>0.978802</td>\n",
       "      <td>[0.8222222222222222, 0.7806451612903226, 0.946...</td>\n",
       "      <td>0.778615</td>\n",
       "      <td>0.0916939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6148148148148148, 0.8129032258064516, 0.853...</td>\n",
       "      <td>0.773664</td>\n",
       "      <td>0.0827355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6888888888888889, 0.9032258064516129, 0.853...</td>\n",
       "      <td>0.772423</td>\n",
       "      <td>0.0745146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6148148148148148, 0.8709677419354839, 0.7, ...</td>\n",
       "      <td>0.760343</td>\n",
       "      <td>0.110972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.8296296296296296, 0.8258064516129032, 0.74,...</td>\n",
       "      <td>0.760276</td>\n",
       "      <td>0.137775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>[0.9979899497487437, 0.9969230769230769, 0.996...</td>\n",
       "      <td>0.997576</td>\n",
       "      <td>[0.8296296296296296, 0.7483870967741936, 0.74,...</td>\n",
       "      <td>0.75443</td>\n",
       "      <td>0.118999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6222222222222222, 0.8387096774193549, 0.78,...</td>\n",
       "      <td>0.752497</td>\n",
       "      <td>0.0811122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>{'Cs': 10, 'class_weight': None, 'cv': None, '...</td>\n",
       "      <td>[0.9105527638190954, 1.0, 0.9734693877551021, ...</td>\n",
       "      <td>0.935248</td>\n",
       "      <td>[0.6888888888888889, 0.9032258064516129, 0.726...</td>\n",
       "      <td>0.751493</td>\n",
       "      <td>0.0741519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>{'C': 1.0, 'average': False, 'class_weight': N...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 0.998001998001998, 1...</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>[0.8518518518518519, 0.9032258064516129, 0.646...</td>\n",
       "      <td>0.74089</td>\n",
       "      <td>0.0853395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>[0.828140703517588, 0.8564102564102564, 0.8285...</td>\n",
       "      <td>0.840237</td>\n",
       "      <td>[0.5407407407407407, 0.7935483870967742, 0.8, ...</td>\n",
       "      <td>0.73768</td>\n",
       "      <td>0.091505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n",
       "      <td>[0.8050251256281407, 0.7887179487179488, 0.808...</td>\n",
       "      <td>0.802231</td>\n",
       "      <td>[0.6518518518518519, 0.8451612903225807, 0.82,...</td>\n",
       "      <td>0.727917</td>\n",
       "      <td>0.0964467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n",
       "      <td>[0.9979899497487437, 1.0, 0.9755102040816327, ...</td>\n",
       "      <td>0.994236</td>\n",
       "      <td>[0.7037037037037037, 0.8451612903225807, 0.573...</td>\n",
       "      <td>0.727828</td>\n",
       "      <td>0.0775724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.7037037037037037, 0.9032258064516129, 0.646...</td>\n",
       "      <td>0.722394</td>\n",
       "      <td>0.0955127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6222222222222222, 0.8774193548387097, 0.806...</td>\n",
       "      <td>0.720165</td>\n",
       "      <td>0.100151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n",
       "      <td>[1.0, 1.0, 0.9724489795918367, 1.0, 0.94510978...</td>\n",
       "      <td>0.991756</td>\n",
       "      <td>[0.7185185185185186, 0.8258064516129032, 0.573...</td>\n",
       "      <td>0.705035</td>\n",
       "      <td>0.0749728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.5481481481481482, 0.7419354838709677, 0.806...</td>\n",
       "      <td>0.694084</td>\n",
       "      <td>0.0895325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>{'alphas': array([ 0.1,  1. , 10. ]), 'class_w...</td>\n",
       "      <td>[0.9708542713567839, 0.9753846153846154, 0.978...</td>\n",
       "      <td>0.971561</td>\n",
       "      <td>[0.7037037037037037, 0.7741935483870968, 0.74,...</td>\n",
       "      <td>0.67105</td>\n",
       "      <td>0.114294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>{'covariance_estimator': None, 'n_components':...</td>\n",
       "      <td>[0.9708542713567839, 0.9753846153846154, 0.978...</td>\n",
       "      <td>0.972861</td>\n",
       "      <td>[0.7037037037037037, 0.7741935483870968, 0.74,...</td>\n",
       "      <td>0.649465</td>\n",
       "      <td>0.11298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.7037037037037037, 0.8064516129032258, 0.453...</td>\n",
       "      <td>0.62512</td>\n",
       "      <td>0.109849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.45925925925925926, 0.5290322580645161, 0.50...</td>\n",
       "      <td>0.495377</td>\n",
       "      <td>0.0379865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "14                            SVC   \n",
       "3      GradientBoostingClassifier   \n",
       "15                          NuSVC   \n",
       "21                  XGBClassifier   \n",
       "2            ExtraTreesClassifier   \n",
       "0              AdaBoostClassifier   \n",
       "5       GaussianProcessClassifier   \n",
       "13           KNeighborsClassifier   \n",
       "4          RandomForestClassifier   \n",
       "6            LogisticRegressionCV   \n",
       "7     PassiveAggressiveClassifier   \n",
       "12                     GaussianNB   \n",
       "11                    BernoulliNB   \n",
       "9                   SGDClassifier   \n",
       "16                      LinearSVC   \n",
       "1               BaggingClassifier   \n",
       "10                     Perceptron   \n",
       "17         DecisionTreeClassifier   \n",
       "8               RidgeClassifierCV   \n",
       "19     LinearDiscriminantAnalysis   \n",
       "18            ExtraTreeClassifier   \n",
       "20  QuadraticDiscriminantAnalysis   \n",
       "\n",
       "                                       MLA Parameters  \\\n",
       "14  {'C': 1.0, 'break_ties': False, 'cache_size': ...   \n",
       "3   {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...   \n",
       "15  {'break_ties': False, 'cache_size': 200, 'clas...   \n",
       "21  {'objective': 'binary:logistic', 'use_label_en...   \n",
       "2   {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...   \n",
       "0   {'algorithm': 'SAMME.R', 'base_estimator': Non...   \n",
       "5   {'copy_X_train': True, 'kernel': None, 'max_it...   \n",
       "13  {'algorithm': 'auto', 'leaf_size': 30, 'metric...   \n",
       "4   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...   \n",
       "6   {'Cs': 10, 'class_weight': None, 'cv': None, '...   \n",
       "7   {'C': 1.0, 'average': False, 'class_weight': N...   \n",
       "12           {'priors': None, 'var_smoothing': 1e-09}   \n",
       "11  {'alpha': 1.0, 'binarize': 0.0, 'class_prior':...   \n",
       "9   {'alpha': 0.0001, 'average': False, 'class_wei...   \n",
       "16  {'C': 1.0, 'class_weight': None, 'dual': True,...   \n",
       "1   {'base_estimator': None, 'bootstrap': True, 'b...   \n",
       "10  {'alpha': 0.0001, 'class_weight': None, 'early...   \n",
       "17  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...   \n",
       "8   {'alphas': array([ 0.1,  1. , 10. ]), 'class_w...   \n",
       "19  {'covariance_estimator': None, 'n_components':...   \n",
       "18  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...   \n",
       "20  {'priors': None, 'reg_param': 0.0, 'store_cova...   \n",
       "\n",
       "                                   MLA Train Accuracy MLA Train Accuracy Mean  \\\n",
       "14  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "3   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "15  [0.9698492462311558, 0.9774358974358974, 0.974...                0.978802   \n",
       "21  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "2   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "0   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "5   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "13  [0.9979899497487437, 0.9969230769230769, 0.996...                0.997576   \n",
       "4   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "6   [0.9105527638190954, 1.0, 0.9734693877551021, ...                0.935248   \n",
       "7   [1.0, 1.0, 1.0, 1.0, 1.0, 0.998001998001998, 1...                  0.9998   \n",
       "12  [0.828140703517588, 0.8564102564102564, 0.8285...                0.840237   \n",
       "11  [0.8050251256281407, 0.7887179487179488, 0.808...                0.802231   \n",
       "9   [0.9979899497487437, 1.0, 0.9755102040816327, ...                0.994236   \n",
       "16  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "1   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "10  [1.0, 1.0, 0.9724489795918367, 1.0, 0.94510978...                0.991756   \n",
       "17  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "8   [0.9708542713567839, 0.9753846153846154, 0.978...                0.971561   \n",
       "19  [0.9708542713567839, 0.9753846153846154, 0.978...                0.972861   \n",
       "18  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "20  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                       1   \n",
       "\n",
       "                                    MLA Test Accuracy MLA Test Accuracy Mean  \\\n",
       "14  [0.8222222222222222, 0.7612903225806451, 0.946...               0.805953   \n",
       "3   [0.6148148148148148, 0.9354838709677419, 0.806...               0.795489   \n",
       "15  [0.8222222222222222, 0.7806451612903226, 0.946...               0.778615   \n",
       "21  [0.6148148148148148, 0.8129032258064516, 0.853...               0.773664   \n",
       "2   [0.6888888888888889, 0.9032258064516129, 0.853...               0.772423   \n",
       "0   [0.6148148148148148, 0.8709677419354839, 0.7, ...               0.760343   \n",
       "5   [0.8296296296296296, 0.8258064516129032, 0.74,...               0.760276   \n",
       "13  [0.8296296296296296, 0.7483870967741936, 0.74,...                0.75443   \n",
       "4   [0.6222222222222222, 0.8387096774193549, 0.78,...               0.752497   \n",
       "6   [0.6888888888888889, 0.9032258064516129, 0.726...               0.751493   \n",
       "7   [0.8518518518518519, 0.9032258064516129, 0.646...                0.74089   \n",
       "12  [0.5407407407407407, 0.7935483870967742, 0.8, ...                0.73768   \n",
       "11  [0.6518518518518519, 0.8451612903225807, 0.82,...               0.727917   \n",
       "9   [0.7037037037037037, 0.8451612903225807, 0.573...               0.727828   \n",
       "16  [0.7037037037037037, 0.9032258064516129, 0.646...               0.722394   \n",
       "1   [0.6222222222222222, 0.8774193548387097, 0.806...               0.720165   \n",
       "10  [0.7185185185185186, 0.8258064516129032, 0.573...               0.705035   \n",
       "17  [0.5481481481481482, 0.7419354838709677, 0.806...               0.694084   \n",
       "8   [0.7037037037037037, 0.7741935483870968, 0.74,...                0.67105   \n",
       "19  [0.7037037037037037, 0.7741935483870968, 0.74,...               0.649465   \n",
       "18  [0.7037037037037037, 0.8064516129032258, 0.453...                0.62512   \n",
       "20  [0.45925925925925926, 0.5290322580645161, 0.50...               0.495377   \n",
       "\n",
       "   MLA Test Accuracy Std  \n",
       "14             0.0750491  \n",
       "3              0.0865326  \n",
       "15             0.0916939  \n",
       "21             0.0827355  \n",
       "2              0.0745146  \n",
       "0               0.110972  \n",
       "5               0.137775  \n",
       "13              0.118999  \n",
       "4              0.0811122  \n",
       "6              0.0741519  \n",
       "7              0.0853395  \n",
       "12              0.091505  \n",
       "11             0.0964467  \n",
       "9              0.0775724  \n",
       "16             0.0955127  \n",
       "1               0.100151  \n",
       "10             0.0749728  \n",
       "17             0.0895325  \n",
       "8               0.114294  \n",
       "19               0.11298  \n",
       "18              0.109849  \n",
       "20             0.0379865  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLA_Wheeze_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
